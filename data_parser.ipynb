{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akashiwo_data_scrape import *\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speacies id\n",
    "spicies_ids = [45, 3]\n",
    "spicies_names = [\"Diaton.csv\", \"shtonela.csv\"]\n",
    "\n",
    "for id, names in zip(spicies_ids, spicies_names):\n",
    "    pull_data(id, \"2011/5/01\", \"2023/10/11\", names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum_names = ['lat', 'lng', 'speciesValueAM', 'speciesValuePM', \n",
    "               'saisuiValueAM', 'saisuiValuePM', 'speciesNameKana', \n",
    "               'maxvalue', 'speciesId', 'icon_size']\n",
    "\n",
    "for name in spicies_names:\n",
    "    remove_colum(colum_names, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"shtonela_info.csv\")\n",
    "pointIds = data[\"pointId\"]\n",
    "gatherYMDs = data[\"gatherYMD\"]\n",
    "filtered_data = remove_duplicates(pointIds, gatherYMDs)\n",
    "pointIds, gatherYMDs = zip(*filtered_data)\n",
    "\n",
    "total_rows = len(filtered_data)\n",
    "split_count = 5\n",
    "rows_per_split = total_rows // split_count\n",
    "\n",
    "header = [\"pointId\", \"gatherYMD\"]\n",
    "\n",
    "split_data = [filtered_data[i:i + rows_per_split] for i in range(0, total_rows, rows_per_split)]\n",
    "\n",
    "for i in range(5):\n",
    "    df = pd.DataFrame(split_data[i], columns=header)\n",
    "    df.to_csv(f\"shatonela_data_{1+i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_data = {}\n",
    "# coordinate_data = {}\n",
    "# main_df = pd.DataFrame(main_data)\n",
    "# coordinate_df = pd.DataFrame(coordinate_data)\n",
    "# headers_to_skip_main = [\"確定値／速報値\", \"事業・調査名\"]\n",
    "\n",
    "def scraper_for_tables(csv):\n",
    "    main_data = {}\n",
    "    coordinate_data = {}\n",
    "    Ids = {}\n",
    "    Ids_df = {}\n",
    "    main_df = pd.DataFrame(main_data)\n",
    "    coordinate_df = pd.DataFrame(coordinate_data)\n",
    "    Ids_temp = pd.DataFrame(Ids)\n",
    "    Ids_df = pd.DataFrame(Ids_df)\n",
    "    headers_to_skip_main = [\"確定値／速報値\", \"事業・調査名\"]\n",
    "\n",
    "    data = pd.read_csv(csv)\n",
    "    pointIds = data['pointId']\n",
    "    gatherYMDs = data['gatherYMD']\n",
    "    filtered_data = zip(pointIds, gatherYMDs)\n",
    "\n",
    "    j = 0\n",
    "    for i, (pointId, gatherYMD) in enumerate(tqdm(filtered_data, total=len(pointIds), dynamic_ncols=True)):\n",
    "        html_data = requests.get(f\"https://akashiwo.jp/private/akashiwoListInit.php?qpoint_id={str(pointId)}&qspecies_id=3&qgather_ymd_s=&qgather_ymd_e={str(gatherYMD)}\")\n",
    "        html_data.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(html_data.text, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        if len(tables) >= 2:\n",
    "            times_to_duplicate, main_df = parse_main_table(tables[1], headers_to_skip_main, main_df)\n",
    "            coordinate_df = parse_coordinate_table(tables[0], coordinate_df, times_to_duplicate)\n",
    "            Ids = {\"pointId\": [pointId] * times_to_duplicate}\n",
    "            Ids_temp = pd.DataFrame(Ids)\n",
    "            Ids_df = pd.concat([Ids_df, Ids_temp], ignore_index=True).fillna(0)\n",
    "        if j == 10:\n",
    "            combined_data_noId = coordinate_df.merge(main_df, left_index=True, right_index=True)\n",
    "            combined_data = Ids_df.merge(combined_data_noId, left_index=True, right_index=True)\n",
    "            combined_data.to_csv(\"shatonela.csv\", index=False)\n",
    "            break\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51752 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/51752 [00:01<1:17:12, 11.17it/s]\n"
     ]
    }
   ],
   "source": [
    "scraper_for_tables(\"shatonela_data_1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
