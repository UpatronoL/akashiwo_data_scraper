{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akashiwo_data_scrape import *\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speacies id\n",
    "spicies_ids = [45, 3]\n",
    "spicies_names = [\"Diaton_info.csv\", \"shtonela_info.csv\"]\n",
    "\n",
    "for id, names in zip(spicies_ids, spicies_names):\n",
    "    pull_data(id, \"2011/5/01\", \"2023/10/11\", names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "colum_names = ['lat', 'lng', 'speciesValueAM', 'speciesValuePM', \n",
    "               'saisuiValueAM', 'saisuiValuePM', 'speciesNameKana', \n",
    "               'maxvalue', 'speciesId', 'icon_size']\n",
    "\n",
    "for name in spicies_names:\n",
    "    remove_colum(colum_names, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(list1, list2):\n",
    "    ziped_list = list(zip(list1, list2))\n",
    "    return list(OrderedDict.fromkeys(ziped_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"shtonela_info.csv\")\n",
    "pointIds = data[\"pointId\"]\n",
    "gatherYMDs = data[\"gatherYMD\"]\n",
    "filtered_dictionary = remove_duplicates(pointIds, gatherYMDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = {}\n",
    "coordinate_data = {}\n",
    "headers_to_skip_main = [\"確定値／速報値\", \"事業・調査名\"]\n",
    "i = 0\n",
    "for pointId, gatherYMD in filtered_dictionary:\n",
    "    html_data = requests.get(f\"https://akashiwo.jp/private/akashiwoListInit.php?qpoint_id={str(pointId)}&qspecies_id=3&qgather_ymd_s=&qgather_ymd_e={str(gatherYMD)}\")\n",
    "    html_data.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(html_data.text, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    times_to_duplicate = parse_main_table(tables[1], headers_to_skip_main, main_data)\n",
    "    parse_coordinate_table(tables[0], coordinate_data, times_to_duplicate)\n",
    "    if(i == 20): break\n",
    "    i += 1\n",
    "\n",
    "df = pd.DataFrame(main_data)\n",
    "df.to_csv(\"hehe.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
